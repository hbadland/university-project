{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:09.988088Z",
     "start_time": "2025-03-08T19:42:09.978336Z"
    }
   },
   "source": [
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import time\n",
    "from jupyterthemes import jtplot\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)\n",
    "\n",
    "wandb.init(project=\"ReLu_test\", sync_tensorboard=True)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/harrybadland-cardiff-university/your_project_name/runs/9ajxn3l2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x321e97920>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:10.577560Z",
     "start_time": "2025-03-08T19:42:10.361016Z"
    }
   },
   "source": [
    "tf.keras.datasets.mnist.load_data(path=\"mnist.npz\");\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:10.728996Z",
     "start_time": "2025-03-08T19:42:10.726205Z"
    }
   },
   "source": [
    "x_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:11.175711Z",
     "start_time": "2025-03-08T19:42:11.172988Z"
    }
   },
   "source": [
    "y_train[2]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:11.468484Z",
     "start_time": "2025-03-08T19:42:11.465791Z"
    }
   },
   "source": [
    "y_train"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:11.771244Z",
     "start_time": "2025-03-08T19:42:11.767464Z"
    }
   },
   "source": [
    "sample = np.zeros(10)\n",
    "sample[1] = 1\n",
    "display(sample)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:12.034074Z",
     "start_time": "2025-03-08T19:42:12.029853Z"
    }
   },
   "source": [
    "y_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:12.399494Z",
     "start_time": "2025-03-08T19:42:12.301033Z"
    }
   },
   "source": [
    "x_train = (x_train.reshape(-1, 28 * 28) / 255).astype('float32')\n",
    "x_test = (x_test.reshape(-1, 28 * 28) / 255).astype('float32')\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:12.590835Z",
     "start_time": "2025-03-08T19:42:12.587449Z"
    }
   },
   "source": [
    "y_train"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:13.094909Z",
     "start_time": "2025-03-08T19:42:13.090514Z"
    }
   },
   "source": [
    "y_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:13.408137Z",
     "start_time": "2025-03-08T19:42:13.404277Z"
    }
   },
   "source": [
    "x_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Procedures**\n",
    "\n",
    "*Forward Pass:*\n",
    "\n",
    "\\\\(Z_i = W_i \\bullet x^T + b_i \\\\)\n",
    "\n",
    "\\\\(A_i = \\sigma(Z_i)\\\\)\n",
    "\n",
    "\\\\(\\hat{y} = A_i\\\\)\n",
    "\n",
    "where \\\\(\\sigma\\\\) is a nonlinear transformation\n",
    "\n",
    "*Loss Function* with regularization\n",
    "\n",
    "\\\\(L(y,\\hat{y}) = -\\frac{1}{m} \\Sigma_j \\Sigma_i y_i log(\\hat{y_i}) + \\frac{\\lambda}{2*m} * (\n",
    "\\Sigma_w w^2)\\\\)\n",
    "\n",
    "*Back propagation: here we use differental equations and use the chain rule first starting with the cost function and work backwards until we get to weights since we want to learn the weights that give a better fit*\n",
    "\n",
    "\\\\(\\frac{\\delta L}{\\delta w_i} = \\frac{\\delta L}{\\delta \\hat{y}} * \\frac{\\delta \\hat{y}}{\\delta z} * \\frac{\\delta z}{\\delta w_i}\\\\)\n",
    "\n",
    "*Update weights*\n",
    "\n",
    "\\\\(w_i = w_i * \\delta w_i - \\frac {(w_i * \\lambda * \\eta)}{m}\\\\)\n",
    "\n",
    "where \\\\(\\eta\\\\) is the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid - Activation function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:42:14.349411Z",
     "start_time": "2025-03-08T19:42:14.339802Z"
    }
   },
   "source": [
    "class MultiLayerPerceptron():\n",
    "    def __init__(self, sizes, epochs=10, l_rate=0.001):\n",
    "        self.sizes = sizes\n",
    "        self.epochs = epochs\n",
    "        self.l_rate = l_rate\n",
    "        self.losses = []\n",
    "        self.accuracy = []\n",
    "\n",
    "        # we save all parameters in the neural network in this dictionary\n",
    "        self.params = self.initialization()\n",
    "\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        if derivative:\n",
    "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def relu(self, x, derivative=False):\n",
    "        if derivative:\n",
    "            return np.where(x > 0, 1, 0)\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def softmax(self, x, derivative=False):\n",
    "        # Numerically stable with large exponentials\n",
    "        exps = np.exp(x - x.max())\n",
    "        if derivative:\n",
    "            return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "        return exps / np.sum(exps, axis=0)\n",
    "\n",
    "    def initialization(self):\n",
    "        # number of nodes in each layer\n",
    "        input_layer=self.sizes[0]\n",
    "        hidden_1=self.sizes[1]\n",
    "        hidden_2=self.sizes[2]\n",
    "        hidden_3=self.sizes[3]\n",
    "        hidden_4=self.sizes[4]\n",
    "        output_layer=self.sizes[5]\n",
    "\n",
    "        params = {\n",
    "            'W1':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "            'W2':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "            'W3':np.random.randn(hidden_3, hidden_2) * np.sqrt(1. / hidden_3),\n",
    "            'W4':np.random.randn(hidden_4, hidden_3) * np.sqrt(1. / hidden_4),\n",
    "            'W5':np.random.randn(output_layer, hidden_4) * np.sqrt(1. / output_layer),\n",
    "        }\n",
    "\n",
    "        return params\n",
    "\n",
    "    def forward_pass(self, x_train):\n",
    "        params = self.params\n",
    "\n",
    "        # input layer activations becomes sample\n",
    "        params['A0'] = x_train\n",
    "\n",
    "        # input layer to hidden layer 1\n",
    "        params['Z1'] = np.dot(params[\"W1\"], params['A0'])\n",
    "        params['A1'] = self.relu(params['Z1'])\n",
    "\n",
    "        # hidden layer 1 to hidden layer 2\n",
    "        params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
    "        params['A2'] = self.relu(params['Z2'])\n",
    "\n",
    "        # hidden layer 2 to hidden 3\n",
    "        params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
    "        params['A3'] = self.relu(params['Z3'])\n",
    "\n",
    "        #Hidden layer 3 to 4\n",
    "        params['Z4'] = np.dot(params[\"W4\"], params['A3'])\n",
    "        params['A4'] = self.relu(params['Z4'])\n",
    "\n",
    "        #Hidden layer 4 to ouput\n",
    "        params['Z5'] = np.dot(params[\"W5\"], params['A4'])\n",
    "        params['A5'] = self.softmax(params['Z5'])\n",
    "\n",
    "        return params['A5']\n",
    "\n",
    "    def backward_pass(self, y_train, output):\n",
    "        '''\n",
    "            This is the backpropagation algorithm, for calculating the updates\n",
    "            of the neural network's parameters.\n",
    "\n",
    "            Note: There is a stability issue that causes warnings. This is \n",
    "                  caused  by the dot and multiply operations on the huge arrays.\n",
    "                  \n",
    "                  RuntimeWarning: invalid value encountered in true_divide\n",
    "                  RuntimeWarning: overflow encountered in exp\n",
    "                  RuntimeWarning: overflow encountered in square\n",
    "        '''\n",
    "        params = self.params\n",
    "        change_w = {}\n",
    "\n",
    "        #Calculate W5 update\n",
    "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z5'], derivative=True)\n",
    "        change_w['W5'] = np.outer(error, params['A4'])\n",
    "\n",
    "        #Calculate W4 Update\n",
    "        error = np.dot(params['W5'].T, error) * self.relu(params['Z4'], derivative=True)\n",
    "        change_w['W4'] = np.outer(error, params['A3'])\n",
    "\n",
    "        # Calculate W3 update\n",
    "        error = np.dot(params['W4'].T, error) * self.relu(params['Z3'], derivative=True)\n",
    "        change_w['W3'] = np.outer(error, params['A2'])\n",
    "\n",
    "        # Calculate W2 update\n",
    "        error = np.dot(params['W3'].T, error) * self.relu(params['Z2'], derivative=True)\n",
    "        change_w['W2'] = np.outer(error, params['A1'])\n",
    "\n",
    "        # Calculate W1 update\n",
    "        error = np.dot(params['W2'].T, error) * self.relu(params['Z1'], derivative=True)\n",
    "        change_w['W1'] = np.outer(error, params['A0'])\n",
    "\n",
    "        return change_w\n",
    "    \n",
    "    def loss_function(self, output, y_train, epsilon=1e-12):\n",
    "        '''\n",
    "            Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "            and predictions. \n",
    "            Input: predictions (N, k) ndarray\n",
    "                   targets (N, k) ndarray        \n",
    "            Returns: scalar\n",
    "        '''\n",
    "        output = np.clip(output, epsilon, 1. - epsilon)\n",
    "        N = output.shape[0]\n",
    "        ce = -np.sum(y_train*np.log(output+1e-9))/N\n",
    "        return ce\n",
    "\n",
    "    def update_network_parameters(self, changes_to_w):\n",
    "        '''\n",
    "            Update network parameters according to update rule from\n",
    "            Stochastic Gradient Descent.\n",
    "\n",
    "            θ = θ - η * ∇J(x, y), \n",
    "                theta θ:            a network parameter (e.g. a weight w)\n",
    "                eta η:              the learning rate\n",
    "                gradient ∇J(x, y):  the gradient of the objective function,\n",
    "                                    i.e. the change for a specific theta θ\n",
    "        '''\n",
    "        \n",
    "        for key, value in changes_to_w.items():\n",
    "            self.params[key] -= self.l_rate * value\n",
    "\n",
    "    def compute_accuracy(self, x_val, y_val):\n",
    "        '''\n",
    "            This function does a forward pass of x, then checks if the indices\n",
    "            of the maximum value in the output equals the indices in the label\n",
    "            y. Then it sums over each prediction and calculates the accuracy.\n",
    "        '''\n",
    "        predictions = []\n",
    "\n",
    "        for x, y in zip(x_val, y_val):\n",
    "            output = (self.forward_pass(x))\n",
    "            pred = np.argmax(output)\n",
    "            predictions.append(pred == np.argmax(y))\n",
    "        \n",
    "        return np.mean(predictions)\n",
    "\n",
    "    def train(self, x_train, y_train, x_test, y_test):\n",
    "        writer = SummaryWriter(\"runs/experiment_name\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        for iteration in tqdm(range(1, self.epochs + 1, 1)):\n",
    "            loss = 0.0\n",
    "            for x, y in zip(x_train, y_train):\n",
    "                output = self.forward_pass(x)\n",
    "                loss += self.loss_function(output, y)\n",
    "                \n",
    "                changes_to_w = self.backward_pass(y, output)\n",
    "                self.update_network_parameters(changes_to_w)\n",
    "\n",
    "            self.losses.append(loss / x_train.shape[0])\n",
    "            acc = self.compute_accuracy(x_test, y_test)\n",
    "            self.accuracy.append(acc)\n",
    "\n",
    "            writer.add_scalar(\"Loss/train\", self.losses[-1], iteration)\n",
    "            writer.add_scalar(\"Accuracy/test\", self.accuracy[-1], iteration)\n",
    "\n",
    "            wandb.log({\"Loss/train\": self.losses[-1], \"Accuracy/test\": self.accuracy[-1]})\n",
    "\n",
    "            print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "                iteration+1, time.time() - start_time, acc * 100\n",
    "            ))\n",
    "        writer.close()\n",
    "        wandb.finish()\n"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T19:45:55.538960Z",
     "start_time": "2025-03-08T19:42:14.706739Z"
    }
   },
   "source": [
    "MLP = MultiLayerPerceptron(sizes=[28 * 28, 128, 64, 32, 16, 10], epochs=25, l_rate=0.01)\n",
    "MLP.train(x_train, y_train, x_test, y_test)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:08<03:31,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Time Spent: 8.83s, Accuracy: 90.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:17<03:22,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Time Spent: 17.65s, Accuracy: 92.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:26<03:13,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Time Spent: 26.45s, Accuracy: 93.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:35<03:04,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Time Spent: 35.18s, Accuracy: 94.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:43<02:55,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Time Spent: 43.89s, Accuracy: 94.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [00:52<02:46,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Time Spent: 52.62s, Accuracy: 95.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [01:01<02:36,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Time Spent: 61.21s, Accuracy: 95.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [01:09<02:27,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Time Spent: 69.82s, Accuracy: 95.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [01:18<02:18,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Time Spent: 78.53s, Accuracy: 95.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [01:27<02:09,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Time Spent: 87.14s, Accuracy: 95.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [01:35<02:01,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Time Spent: 95.79s, Accuracy: 95.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [01:44<01:52,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Time Spent: 104.48s, Accuracy: 95.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [01:53<01:43,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Time Spent: 113.12s, Accuracy: 95.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [02:01<01:34,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Time Spent: 121.67s, Accuracy: 95.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [02:10<01:26,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Time Spent: 130.33s, Accuracy: 96.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [02:18<01:17,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Time Spent: 138.94s, Accuracy: 96.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [02:27<01:09,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Time Spent: 147.58s, Accuracy: 96.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [02:36<01:00,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Time Spent: 156.18s, Accuracy: 96.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [02:44<00:51,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Time Spent: 164.93s, Accuracy: 96.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [02:53<00:43,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Time Spent: 173.56s, Accuracy: 96.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [03:02<00:34,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Time Spent: 182.18s, Accuracy: 96.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [03:11<00:26,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Time Spent: 191.03s, Accuracy: 96.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [03:19<00:17,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Time Spent: 199.99s, Accuracy: 96.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [03:29<00:08,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Time Spent: 209.08s, Accuracy: 10.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [03:37<00:00,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Time Spent: 217.97s, Accuracy: 10.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy/test</td><td>▇██████████▇█████████████████▁█████████▁</td></tr><tr><td>Loss/train</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy/test</td><td>0.1009</td></tr><tr><td>Loss/train</td><td>1.86676</td></tr><tr><td>global_step</td><td>25</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">usual-eon-1</strong> at: <a href='https://wandb.ai/harrybadland-cardiff-university/your_project_name/runs/9ajxn3l2' target=\"_blank\">https://wandb.ai/harrybadland-cardiff-university/your_project_name/runs/9ajxn3l2</a><br> View project at: <a href='https://wandb.ai/harrybadland-cardiff-university/your_project_name' target=\"_blank\">https://wandb.ai/harrybadland-cardiff-university/your_project_name</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250308_194138-9ajxn3l2/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
